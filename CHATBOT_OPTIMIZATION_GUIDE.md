# ì±—ë´‡ ë‹µë³€ ì†ë„ ìµœì í™” ê°€ì´ë“œ

## ì„œìš¸ê²½ì œì‹ ë¬¸ ê²½ì œìš© ì±—ë´‡ ì„±ëŠ¥ ê°œì„  ë°©ì•ˆ

## ğŸš€ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìµœì í™” ë°©ì•ˆ

### 1. Cloud Run ì„¤ì • ìµœì í™”

#### A. ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (ì½œë“œ ìŠ¤íƒ€íŠ¸ ì œê±°)

```bash
# ì½œë“œ ìŠ¤íƒ€íŠ¸ ìµœì†Œí™” - ìµœì†Œ 1ê°œ ì¸ìŠ¤í„´ìŠ¤ ìƒì‹œ ìœ ì§€
gcloud run services update sedaily-chatbot \
  --region asia-northeast3 \
  --min-instances 1 \
  --max-instances 10
```

#### B. CPU ë¶€ìŠ¤íŠ¸ í™œì„±í™”

```bash
# CPU ë¶€ìŠ¤íŠ¸ë¡œ ì´ˆê¸° ìš”ì²­ ì²˜ë¦¬ ì†ë„ í–¥ìƒ
gcloud run services update sedaily-chatbot \
  --region asia-northeast3 \
  --cpu-boost
```

#### C. ë™ì‹œì„± ìµœì í™”

```bash
# ë™ì‹œì„±ì„ 50ìœ¼ë¡œ ì¤„ì—¬ì„œ ì¸ìŠ¤í„´ìŠ¤ë‹¹ ì²˜ë¦¬ í’ˆì§ˆ í–¥ìƒ
gcloud run services update sedaily-chatbot \
  --region asia-northeast3 \
  --concurrency 50
```

### 2. ë©”ëª¨ë¦¬ ë° CPU ìµœì í™”

#### A. ë©”ëª¨ë¦¬ ì¦ì„¤ (í˜„ì¬ 2Gi â†’ 4Gi)

```bash
gcloud run services update sedaily-chatbot \
  --region asia-northeast3 \
  --memory 4Gi \
  --cpu 2
```

#### B. íƒ€ì„ì•„ì›ƒ ì„¤ì • (í˜„ì¬ 300ì´ˆ â†’ 60ì´ˆ)

```bash
# ì‘ë‹µ ì†ë„ê°€ ê°œì„ ë˜ë©´ íƒ€ì„ì•„ì›ƒì„ ì¤„ì—¬ì„œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
gcloud run services update sedaily-chatbot \
  --region asia-northeast3 \
  --timeout 60
```

## ğŸ”§ ì½”ë“œ ë ˆë²¨ ìµœì í™”

### 3. LLM ëª¨ë¸ ìµœì í™”

#### A. ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©

```python
# modules/unified_chatbot.pyì—ì„œ ëª¨ë¸ ë³€ê²½
self.llm = ChatOpenAI(
    model="gpt-4o-mini",      # í˜„ì¬ ì‚¬ìš© ì¤‘ - ì´ë¯¸ ë¹ ë¥¸ ëª¨ë¸
    temperature=0.1,
    max_tokens=1000,          # í† í° ìˆ˜ ì œí•œìœ¼ë¡œ ì†ë„ í–¥ìƒ
    timeout=30,               # API íƒ€ì„ì•„ì›ƒ ì„¤ì •
    openai_api_key=self.openai_api_key
)
```

#### B. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í™œìš©

```python
# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì ì§„ì  ë‹µë³€ ì œê³µ (ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŒ)
def generate_stream_response(self, query: str):
    response = self.llm.stream(query)
    for chunk in response:
        yield chunk.content
```

### 4. ë²¡í„° ê²€ìƒ‰ ìµœì í™”

#### A. ì„ë² ë”© ëª¨ë¸ ìµœì í™”

```python
# ë” ë¹ ë¥¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
self.embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",  # ì´ë¯¸ ì‚¬ìš© ì¤‘ - ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸
    openai_api_key=self.openai_api_key,
    timeout=10  # íƒ€ì„ì•„ì›ƒ ì¶”ê°€
)
```

#### B. ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì œí•œ

```python
# ê²€ìƒ‰ ê²°ê³¼ë¥¼ 3ê°œë¡œ ì œí•œí•˜ì—¬ ì†ë„ í–¥ìƒ
def search_internal_documents(self, query: str, k: int = 3) -> List[Document]:
    if not self.retriever:
        return []
    return self.retriever.get_relevant_documents(query)[:k]
```

### 5. ìºì‹± ì „ëµ êµ¬í˜„

#### A. Redis ìºì‹± ì‹œìŠ¤í…œ ë„ì…

```python
import redis
from functools import wraps

# Redis ì—°ê²° (Cloud Memorystore ì‚¬ìš© ê¶Œì¥)
redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_response(expiry=3600):  # 1ì‹œê°„ ìºì‹œ
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache_key = f"chatbot:{hash(str(args)+str(kwargs))}"
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            result = func(*args, **kwargs)
            redis_client.setex(cache_key, expiry, json.dumps(result))
            return result
        return wrapper
    return decorator

@cache_response(expiry=1800)  # 30ë¶„ ìºì‹œ
def process_query(self, query: str):
    # ê¸°ì¡´ ë¡œì§
    pass
```

#### B. ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹± (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

```python
from functools import lru_cache
import hashlib

class UnifiedChatbot:
    def __init__(self):
        self.response_cache = {}
        self.cache_max_size = 100

    def get_cached_response(self, query: str) -> Optional[str]:
        query_hash = hashlib.md5(query.encode()).hexdigest()
        return self.response_cache.get(query_hash)

    def cache_response(self, query: str, response: str):
        if len(self.response_cache) >= self.cache_max_size:
            # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ ìºì‹œ ì œê±°
            oldest_key = next(iter(self.response_cache))
            del self.response_cache[oldest_key]

        query_hash = hashlib.md5(query.encode()).hexdigest()
        self.response_cache[query_hash] = response
```

### 6. ë¬¸ì„œ ë¡œë”© ìµœì í™”

#### A. ì§€ì—° ë¡œë”© êµ¬í˜„

```python
def lazy_load_documents(self):
    """í•„ìš”í•  ë•Œë§Œ ë¬¸ì„œ ë¡œë“œ"""
    if not self.docs:
        self.load_documents()
    return self.docs

def preload_common_queries(self):
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¿¼ë¦¬ ë¯¸ë¦¬ ì²˜ë¦¬"""
    common_queries = [
        "ê¸°ì¤€ê¸ˆë¦¬ë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì¸í”Œë ˆì´ì…˜ì˜ ì›ì¸ì€?",
        "ì£¼ì‹ì‹œì¥ ì „ë§"
    ]
    for query in common_queries:
        self.process_query(query)
```

## ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

### 7. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¶”ê°€

#### A. ì‘ë‹µ ì‹œê°„ ì¸¡ì •

```python
import time
from functools import wraps

def measure_performance(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()

        logger.info(f"{func.__name__} ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        return result
    return wrapper

@measure_performance
def process_query(self, query: str):
    # ê¸°ì¡´ ë¡œì§
    pass
```

#### B. ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
class PerformanceMetrics:
    def __init__(self):
        self.query_count = 0
        self.total_response_time = 0
        self.avg_response_time = 0
        self.cache_hits = 0
        self.cache_misses = 0

    def record_query(self, response_time: float, cache_hit: bool):
        self.query_count += 1
        self.total_response_time += response_time
        self.avg_response_time = self.total_response_time / self.query_count

        if cache_hit:
            self.cache_hits += 1
        else:
            self.cache_misses += 1

    def get_stats(self):
        cache_rate = self.cache_hits / (self.cache_hits + self.cache_misses) * 100
        return {
            "avg_response_time": self.avg_response_time,
            "total_queries": self.query_count,
            "cache_hit_rate": cache_rate
        }
```

## ğŸ›  ì¦‰ì‹œ ì ìš©í•  ìˆ˜ ìˆëŠ” deploy.sh ìˆ˜ì •ì‚¬í•­

### 8. ìµœì í™”ëœ ë°°í¬ ì„¤ì •

```bash
# CPU ë¶€ìŠ¤íŠ¸ ë° ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • ì¶”ê°€
gcloud run deploy ${SERVICE_NAME} \
  --image gcr.io/${PROJECT_ID}/${IMAGE_NAME}:${VERSION} \
  --platform managed \
  --region ${REGION} \
  --allow-unauthenticated \
  --memory 4Gi \
  --cpu 2 \
  --timeout 60 \
  --concurrency 50 \
  --max-instances 10 \
  --min-instances 1 \
  --cpu-boost \
  --set-env-vars "${ENV_VARS}" \
  --project ${PROJECT_ID}
```

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„  íš¨ê³¼

### ê°œì„  ì „í›„ ë¹„êµ

| ìµœì í™” í•­ëª©    | ê°œì„  ì „ | ê°œì„  í›„ | íš¨ê³¼             |
| -------------- | ------- | ------- | ---------------- |
| ì½œë“œ ìŠ¤íƒ€íŠ¸    | 3-5ì´ˆ   | 0ì´ˆ     | ì¦‰ì‹œ ì‘ë‹µ        |
| í‰ê·  ì‘ë‹µ ì‹œê°„ | 8-12ì´ˆ  | 3-5ì´ˆ   | 60% ë‹¨ì¶•         |
| ìºì‹œ ì ì¤‘ë¥     | 0%      | 30-50%  | ë°˜ë³µ ì§ˆë¬¸ ê³ ì†í™” |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰  | 2Gi     | 4Gi     | ì•ˆì •ì„± í–¥ìƒ      |
| ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ | 100     | 50      | í’ˆì§ˆ í–¥ìƒ        |

## ğŸš€ ë‹¨ê³„ë³„ ì ìš© ìˆœì„œ

### Phase 1: ì¦‰ì‹œ ì ìš© (5ë¶„)

1. Cloud Run ì„¤ì • ë³€ê²½ (ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤, CPU ë¶€ìŠ¤íŠ¸)
2. ë©”ëª¨ë¦¬ 4Gië¡œ ì¦ì„¤

### Phase 2: ì½”ë“œ ìˆ˜ì • (30ë¶„)

1. ë©”ëª¨ë¦¬ ìºì‹± êµ¬í˜„
2. API íƒ€ì„ì•„ì›ƒ ì„¤ì •
3. ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì œí•œ

### Phase 3: ê³ ê¸‰ ìµœì í™” (2ì‹œê°„)

1. Redis ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
3. ì§€ì—° ë¡œë”© êµ¬í˜„

## ğŸ“‹ ëª¨ë‹ˆí„°ë§ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] í‰ê·  ì‘ë‹µ ì‹œê°„ < 5ì´ˆ
- [ ] ìºì‹œ ì ì¤‘ë¥  > 30%
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  < 80%
- [ ] ì—ëŸ¬ìœ¨ < 1%
- [ ] ì½œë“œ ìŠ¤íƒ€íŠ¸ ë°œìƒ ë¹ˆë„ < 5%

## ğŸ’¡ ì¶”ê°€ ê¶Œì¥ì‚¬í•­

1. **CDN ì‚¬ìš©**: ì •ì  íŒŒì¼ì€ Cloud CDNìœ¼ë¡œ ë¶„ë¦¬
2. **ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”**: Firestore ë˜ëŠ” Cloud SQL í™œìš©
3. **ë¡œë“œ ë°¸ëŸ°ì‹±**: íŠ¸ë˜í”½ ì¦ê°€ ì‹œ ë©€í‹° ë¦¬ì „ ë°°í¬
4. **A/B í…ŒìŠ¤íŒ…**: ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ì„¤ì • ë¹„êµ í…ŒìŠ¤íŠ¸
